{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Y5H90HV799Qn",
    "outputId": "350119f1-e4cc-4a6d-ee32-020712b562db"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "#import necessary libraries.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "layer = tf.keras.layers\n",
    "\n",
    "print('check tensorflow version : ', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data API는 데이터셋을 모델에 연결해주기 위한 복합적인 입력 파이프라인을 구축할 수 있게 도와줍니다.\n",
    "\n",
    "다수의 분산된 파일로부터 통합된 데이터를 만들어야 하는 경우나, 데이터 전처리, 미니배치, 랜덤셔플링 등의 데이터 파이프라인을 위한 복잡한 구조를 높은 추상성으로 간단하게 제어할 수 있는 인터페이스를 제공합니다.\n",
    "\n",
    "https://www.tensorflow.org/guide/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. from_tensor_slices : python으로부터 데이터 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
    "\n",
    "dataset1.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
    "   (tf.random.uniform([4]),\n",
    "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
    "\n",
    "dataset2.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "\n",
    "dataset3.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset3.take(1):\n",
    "    print(i)\n",
    "#     print(i[0])\n",
    "#     print('\\n-------------------------------------------------------------------\\n')\n",
    "#     print(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메모리 공간 위 이미지를 가져오는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = train\n",
    "images = images/255\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TextLineDataset : text file로부터 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
    "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
    "\n",
    "file_paths = [\n",
    "    tf.keras.utils.get_file(file_name, directory_url+file_name)\n",
    "    for file_name in file_names ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in dataset.take(1):\n",
    "  print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = dataset.shuffle(buffer_size=10000).batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in new_dataset.take(1):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TextLineDataset : csv 파일로부터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "df = pd.read_csv(titanic_file, index_col=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_slices = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "\n",
    "for feature_batch in titanic_slices.take(1):\n",
    "  for key, value in feature_batch.items():\n",
    "    print(\"  {!r:20s}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-XSanJS99Qz"
   },
   "source": [
    "# keras model build\n",
    "\n",
    "keras에서 모델을 만들기 위해 알아야 할 3가지 자료형인 layer, tensor, model이 있다.\n",
    "layer는 인공신경망을 구성하는 하위 계층을 의미하고, tensor는 layer와 layer 사이의 입력과 출력을 말한다. TensorFlow는 flow graph의 형태이기 때문에 tensor는 데이터에 따라 계속 변하는 변동 변수이기 때문에 특정 값을 가진다고 할 수 없음. 그러나 tf 2.0부터 tensor의 값을 tensor.numpy()의 형태로 쉽게 확인할 수 있음. 마지막으로 model은 layer를 엮은 네트워크 객체라고 할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQzYPc8d99Q1"
   },
   "outputs": [],
   "source": [
    "#layer는 tf.keras.layers 아래의 클래스로 만들 수 있다.\n",
    "d1 = tf.keras.layers.Dense(32, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3KAyO91o99Q5",
    "outputId": "a9b3c881-b59e-4ef3-f11c-c9b55360e984"
   },
   "outputs": [],
   "source": [
    "print(type(d1)) #레이어의 타입을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WKxUmgGU99Q-",
    "outputId": "1c9d2b20-8fc3-463e-f4d1-9e43aa215c0d"
   },
   "outputs": [],
   "source": [
    "# 각 layer 클래스는 method로 init, build, call를 갖는다. \n",
    "# init은 객체가 만들어지는 단계이고, tf.keras.layers.Dense(32, activation='relu')를 선언했을 때 실행된다.\n",
    "# build는 실제로 layer가 파라미터를 갖는 단계, call은 layer가 가진 parameter로 데이터를 계산하는 단계이다.\n",
    "\n",
    "print(d1.get_weights()) #weight는 build되지 않았기 때문에 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "3i4f9Zqp99RG",
    "outputId": "3c96448d-23dc-43bb-8b91-972a2eb35d19"
   },
   "outputs": [],
   "source": [
    "# build는 layer가 첫 번째로 call됐을 때 파라미터를 생성함. 특정 데이터를 입력하기 애매하기 때문에 보통 tf.keras.Input을 사용함.\n",
    "inputs = tf.keras.Input(shape=(784)) #shape를 정해줌. \n",
    "#layer의 input shape이 정해져야 layer가 build 단계에서 파라미터의 shape을 결정할 수 있음.\n",
    "print('type of inputs', type(inputs))\n",
    "d1_output = d1(inputs)\n",
    "print('weights of d1', d1.get_weights(), \n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'weight shape : ', d1.get_weights()[0].shape,\n",
    "      '\\n-------------------------------------------------\\n',\n",
    "      'bias shape : ', d1.get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "blVFGmVx99RK",
    "outputId": "21ab174b-2df7-4986-8752-24a5cf9b7e80"
   },
   "outputs": [],
   "source": [
    "# build가 된 layer는 이제 입력으로 데이터를 받으면 output을 계산한다.\n",
    "d1_output = d1(np.ones([1,784], dtype=np.float32))\n",
    "print('d1_output의 타입', type(d1_output)) # 계산 결과의 자료형은 tensor\n",
    "print('\\n-------------------------------------------------\\n')\n",
    "print(d1_output.numpy()) #tf 2.0은 eager excution을 default로 제공하여 현재 tensor가 가지고 있는 값을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukx6TzCO99RO"
   },
   "outputs": [],
   "source": [
    "#model은 다음과 같이 첫 번째 layer의 input tensor와 마지막 layer의 output tensor를 입력 받아 생성한다.\n",
    "\n",
    "inputs = tf.keras.Input(shape=(64), name='data_input')\n",
    "d_1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "d_1_output = d_1(inputs)\n",
    "# d_1 = tf.keras.layers.Dense(32, activation='relu')(inputs)와 같이 init 후 inputs를 넣어서 build를 동시에 수행할 수 있음.\n",
    "d_2_output = tf.keras.layers.Dense(64, activation='relu')(d_1_output)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=d_2_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "E7xs9VKC99RS",
    "outputId": "999bea24-d8d2-45fc-b619-d9c1ae9a6561"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "FTS5jydD99RV",
    "outputId": "39286c57-af4b-42c3-bead-8bb3ae9968ce"
   },
   "outputs": [],
   "source": [
    "#make sure you have already graphviz, pydot, pydotplus libraries.\n",
    "tf.keras.utils.plot_model(model, 'my_first_model_with_shape_info.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLT518BV99RZ"
   },
   "source": [
    "## 1. Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of train dataset : \", x_train.shape)\n",
    "print(\"The shape of test dataset : \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32).repeat()\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "import math\n",
    "steps_per_epoch=math.ceil(60000/32)\n",
    "model.fit(train_ds, epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28,1))  # Returns a placeholder tensor\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# A layer instance is callable on a tensor, and returns a tensor.\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_ds))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compile step specifies the training configuration.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "import math\n",
    "steps_per_epoch=math.ceil(60000/32)\n",
    "model.fit(train_ds, epochs=5, steps_per_epoch=steps_per_epoch)\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ill1SARf99Rd"
   },
   "source": [
    "# Split pre-trained model for customized transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Z5KfdwAS99Re",
    "outputId": "e37117a8-b7e2-4312-a0c9-8c64ae36f7c2"
   },
   "outputs": [],
   "source": [
    "# You can take famous image processing architecture, resnet101.\n",
    "\n",
    "\n",
    "#https://keras.io/applications/#usage-examples-for-image-classification-models\n",
    "\n",
    "'''\n",
    "include_top: whether to include the fully-connected layer at the top of the network.\n",
    "weights: one of None (random initialization) or 'imagenet' (pre-training on ImageNet).\n",
    "input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n",
    "input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (299, 299, 3). It should have exactly 3 inputs channels, and width and height should be no smaller than 71. E.g. (150, 150, 3) would be one valid value.\n",
    "pooling: Optional pooling mode for feature extraction when include_top is False.\n",
    "None means that the output of the model will be the 4D tensor output of the last convolutional layer.\n",
    "'avg' means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor.\n",
    "'max' means that global max pooling will be applied.\n",
    "classes: optional number of classes to classify images into, only to be specified if include_top is  True, and if no weights argument is specified.\n",
    "'''\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(240, 240, 3))\n",
    "resnet101 = tf.keras.applications.ResNet101(include_top=False, weights='imagenet', input_tensor=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "h0792iNG99Ri",
    "outputId": "1db5a01a-a34a-4de3-f42a-c58ee271a668"
   },
   "outputs": [],
   "source": [
    "for l in resnet101.layers[:10]:\n",
    "  print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nzdMSnqC99Rl",
    "outputId": "fb0ba806-48ca-4203-c670-08daa01b195d"
   },
   "outputs": [],
   "source": [
    "#plot the architecture of resnet 101\n",
    "tf.keras.utils.plot_model(resnet101, 'resnet101.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcXDexqf99Rp"
   },
   "outputs": [],
   "source": [
    "model_input = resnet101.get_layer('input_5').input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LFCPgNlJ99Rt"
   },
   "outputs": [],
   "source": [
    "model_output = resnet101.get_layer('conv4_block23_out').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJ-warkc99R1"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.Model(inputs=model_input, outputs=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOeT6Az599R6",
    "outputId": "94229e17-aae0-4fb3-9475-77fd3d129021"
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAiZP4Nv99R-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP5Y5hZa99SF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fSAlme4h99SK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Keras_funtional_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
