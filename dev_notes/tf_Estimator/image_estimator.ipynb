{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to use the TF Estimator APIs\n",
    "0. Prepare CIFAR-10 Dataset (Binary Format)\n",
    "1. Define parameters\n",
    "2. Define data input pipeline\n",
    "3. Define features\n",
    "4. Define a model\n",
    "5. Define serving function\n",
    "6. Train, evaluate and export a model\n",
    "7. Evaluate with Estimator\n",
    "8. Prediction with Exported Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare CIFAR-10 Dataset (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download_and_extract(\n",
    "  dest_directory='data',\n",
    "  data_url='http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'):\n",
    "  \n",
    "  \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
    "  dest_directory = dest_directory\n",
    "  if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "  filename = data_url.split('/')[-1]\n",
    "  filepath = os.path.join(dest_directory, filename)\n",
    "  if not os.path.exists(filepath):\n",
    "    def _progress(count, block_size, total_size):\n",
    "      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n",
    "          filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "      sys.stdout.flush()\n",
    "    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "  extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "  if not os.path.exists(extracted_dir_path):\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "maybe_download_and_extract(DATA_DIR, DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(index=0, filepath='data/cifar-10-batches-bin/data_batch_5.bin'):\n",
    "  bytestream = open(filepath, mode='rb')\n",
    "\n",
    "  label_bytes_length = 1\n",
    "  image_bytes_length = (32 ** 2) * 3\n",
    "  record_bytes_length = label_bytes_length + image_bytes_length\n",
    "\n",
    "  bytestream.seek(record_bytes_length * index, 0)\n",
    "  label_bytes = bytestream.read(label_bytes_length)\n",
    "  image_bytes = bytestream.read(image_bytes_length)\n",
    "\n",
    "  label = np.frombuffer(label_bytes, dtype=np.uint8)  \n",
    "  image = np.frombuffer(image_bytes, dtype=np.uint8)\n",
    "  \n",
    "  image = np.reshape(image, [3, 32, 32])\n",
    "  image = np.transpose(image, [1, 2, 0])\n",
    "  image = image.astype(np.float32)\n",
    "  \n",
    "  result = {\n",
    "    'image': image,\n",
    "    'label': label,\n",
    "  }\n",
    "  bytestream.close()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "result = extract_data(np.random.randint(1000))\n",
    "plt.imshow(result['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS():\n",
    "  pass\n",
    "\n",
    "FLAGS.batch_size = 200\n",
    "FLAGS.max_steps = 1000\n",
    "FLAGS.eval_steps = 100\n",
    "FLAGS.save_checkpoints_steps = 100\n",
    "FLAGS.tf_random_seed = 19851211\n",
    "FLAGS.model_name = 'cnn-model-02'\n",
    "FLAGS.use_checkpoint = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(raw_record):\n",
    "  # Every record consists of a label followed by the image, with a fixed number\n",
    "  # of bytes for each.\n",
    "  label_bytes = 1\n",
    "  image_bytes = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH\n",
    "  record_bytes = label_bytes + image_bytes\n",
    "  \n",
    "  # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "  record_vector = tf.decode_raw(raw_record, tf.uint8)\n",
    "  \n",
    "  # The first byte represents the label, which we convert from uint8 to int32\n",
    "  # and then to one-hot.\n",
    "  label = tf.cast(record_vector[0], tf.int32)\n",
    "  label = tf.one_hot(label, NUM_CLASSES)\n",
    "  \n",
    "  # The remaining bytes after the label represent the image, which we reshape\n",
    "  # from [depth * height * width] to [depth, height, width].\n",
    "  depth_major = tf.reshape(\n",
    "    record_vector[label_bytes:record_bytes], [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "  \n",
    "  # Convert from [depth, height, width] to [height, width, depth], and cast as\n",
    "  # float32.\n",
    "  image = tf.cast(tf.transpose(depth_major, [1, 2, 0]), tf.float32)\n",
    "  \n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, is_training=False):\n",
    "  \"\"\"Preprocess a single image of layout [height, width, depth].\"\"\"\n",
    "  if is_training:\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_image_with_crop_or_pad(\n",
    "        image, IMAGE_HEIGHT + 8, IMAGE_WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [_HEIGHT, _WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  # Subtract off the mean and divide by the variance of the pixels.\n",
    "  image = tf.image.per_image_standardization(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_fn(file_names, mode=tf.estimator.ModeKeys.EVAL, batch_size=1):\n",
    "  def _input_fn():\n",
    "    label_bytes = 1\n",
    "    image_bytes = IMAGE_HEIGHT * IMAGE_WIDTH * IMAGE_DEPTH\n",
    "    record_bytes = label_bytes + image_bytes\n",
    "    dataset = tf.data.FixedLengthRecordDataset(filenames=file_names,\n",
    "                                               record_bytes=record_bytes)\n",
    "\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    if is_training:\n",
    "      buffer_size = batch_size * 2 + 1\n",
    "      dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    dataset = dataset.map(parse_record)\n",
    "    dataset = dataset.map(lambda image, label: (preprocess_image(image, is_training), label))\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(2 * batch_size)\n",
    "\n",
    "    # Batch results by up to batch_size, and then fetch the tuple from the\n",
    "    # iterator.\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "\n",
    "    features = {'images': images}\n",
    "    return features, labels\n",
    "  \n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns():\n",
    "  feature_columns = {\n",
    "    'images': tf.feature_column.numeric_column('images', (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH)),\n",
    "  }\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Columns: {'images': _NumericColumn(key='images', shape=(32, 32, 3), default_value=None, dtype=tf.float32, normalizer_fn=None)}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = get_feature_columns()\n",
    "print(\"Feature Columns: {}\".format(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='images', shape=(32, 32, 3), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(get_feature_columns().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "  # 1st Convolutional Layer                                                                                                                 \n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=images, filters=64, kernel_size=[5, 5], padding='same',\n",
    "      activation=tf.nn.relu, name='conv1')\n",
    "  pool1 = tf.layers.max_pooling2d(\n",
    "      inputs=conv1, pool_size=[3, 3], strides=2, name='pool1')\n",
    "  norm1 = tf.nn.lrn(\n",
    "      pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "  # 2nd Convolutional Layer                                                                                                                 \n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=norm1, filters=64, kernel_size=[5, 5], padding='same',\n",
    "      activation=tf.nn.relu, name='conv2')\n",
    "  norm2 = tf.nn.lrn(\n",
    "      conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "  pool2 = tf.layers.max_pooling2d(\n",
    "      inputs=norm2, pool_size=[3, 3], strides=2, name='pool2')\n",
    "\n",
    "  # Flatten Layer                                                                                                                           \n",
    "  shape = pool2.get_shape()\n",
    "  pool2_ = tf.reshape(pool2, [-1, shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "  # 1st Fully Connected Layer                                                                                                               \n",
    "  dense1 = tf.layers.dense(\n",
    "      inputs=pool2_, units=384, activation=tf.nn.relu, name='dense1')\n",
    "\n",
    "  # 2nd Fully Connected Layer                                                                                                               \n",
    "  dense2 = tf.layers.dense(\n",
    "      inputs=dense1, units=192, activation=tf.nn.relu, name='dense2')\n",
    "\n",
    "  # 3rd Fully Connected Layer (Logits)                                                                                                      \n",
    "  logits = tf.layers.dense(\n",
    "      inputs=dense2, units=NUM_CLASSES, activation=tf.nn.relu, name='logits')\n",
    "\n",
    "  return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  # Create the input layers from the features                                                                                               \n",
    "  feature_columns = list(get_feature_columns().values())\n",
    "\n",
    "  images = tf.feature_column.input_layer(\n",
    "    features=features, feature_columns=feature_columns)\n",
    "\n",
    "  images = tf.reshape(\n",
    "    images, shape=(-1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH))\n",
    "\n",
    "  # Calculate logits through CNN                                                                                                            \n",
    "  logits = inference(images)\n",
    "\n",
    "  if mode in (tf.estimator.ModeKeys.PREDICT, tf.estimator.ModeKeys.EVAL):\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "\n",
    "  if mode in (tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL):\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    label_indices = tf.argmax(input=labels, axis=1)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=labels, logits=logits)\n",
    "    tf.summary.scalar('cross_entropy', loss)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'classes': predicted_indices,\n",
    "        'probabilities': probabilities\n",
    "    }\n",
    "    export_outputs = {\n",
    "        'predictions': tf.estimator.export.PredictOutput(predictions)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define a serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "\n",
    "  receiver_tensor = {'images': tf.placeholder(\n",
    "    shape=[None, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_DEPTH], dtype=tf.float32)}\n",
    "  features = {'images': tf.map_fn(preprocess_image, receiver_tensor['images'])}\n",
    "  \n",
    "  return tf.estimator.export.ServingInputReceiver(features, receiver_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train, evaluate and export a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'trained_models/{}'.format(FLAGS.model_name)\n",
    "train_data_files = ['data/cifar-10-batches-bin/data_batch_{}.bin'.format(i) for i in range(1,5)]\n",
    "valid_data_files = ['data/cifar-10-batches-bin/data_batch_5.bin']\n",
    "test_data_files = ['data/cifar-10-batches-bin/test_batch.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = tf.estimator.RunConfig(\n",
    "  save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "  tf_random_seed=FLAGS.tf_random_seed,\n",
    "  model_dir=model_dir\n",
    ")\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "\n",
    "# There is another Exporter named FinalExporter\n",
    "exporter = tf.estimator.LatestExporter(\n",
    "  name='Servo',\n",
    "  serving_input_receiver_fn=serving_input_fn,\n",
    "  assets_extra=None,\n",
    "  as_text=False,\n",
    "  exports_to_keep=5)\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "  input_fn=generate_input_fn(file_names=train_data_files,\n",
    "                             mode=tf.estimator.ModeKeys.TRAIN,\n",
    "                             batch_size=FLAGS.batch_size),\n",
    "  max_steps=FLAGS.max_steps)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "  input_fn=generate_input_fn(file_names=valid_data_files,\n",
    "                             mode=tf.estimator.ModeKeys.EVAL,\n",
    "                             batch_size=FLAGS.batch_size),\n",
    "  steps=FLAGS.eval_steps, exporters=exporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLAGS.use_checkpoint:\n",
    "  print(\"Removing previous artifacts...\")\n",
    "  shutil.rmtree(model_dir, ignore_errors=True)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate with Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = generate_input_fn(file_names=test_data_files,\n",
    "                                  mode=tf.estimator.ModeKeys.EVAL,\n",
    "                                  batch_size=1000)\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn, config=run_config)\n",
    "print(estimator.evaluate(input_fn=test_input_fn, steps=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate with an exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = model_dir + '/export/Servo/'\n",
    "saved_model_dir = os.path.join(export_dir, os.listdir(export_dir)[-1]) \n",
    "\n",
    "predictor_fn = tf.contrib.predictor.from_saved_model(\n",
    "  export_dir = saved_model_dir,\n",
    "  signature_def_key='predictions')\n",
    "\n",
    "N = 1000\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "for i in range(N):\n",
    "  result = extract_data(i, filepath='data/cifar-10-batches-bin/test_batch.bin')\n",
    "  images.append(result['image'])\n",
    "  labels.append(result['label'][0])\n",
    "\n",
    "output = predictor_fn({'images': images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([a==r for a, r in zip(labels, output['classes'])]) / float(N)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
