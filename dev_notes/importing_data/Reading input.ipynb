{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/datasets\n",
    "\n",
    "https://www.tensorflow.org/guide/performance/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading inputs\n",
    "\n",
    "tf.data API를 통해 우리는 on-memory(from_tensor_slice), generator(from_generator), file(TFrecord) 등과 같이 다양한 input source로부터 dataset을 만들고, interleave, map, filter, reduce 등과 같은 함수로 dataset을 재가공 또는 수정하여 최종적으로 iterator를 통해 데이터를 가져오는 방식임을 배웠다.\n",
    "\n",
    "이제 이번 코드에서는 실제 각 case 별로 데이터를 읽어 graph로 가져오는 코드를 수행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading images in categorical directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_filenames_and_classes(dataset_dir):\n",
    "      flower_root = os.path.join(dataset_dir, 'flower_photos')\n",
    "      directories = []\n",
    "      class_names = []\n",
    "      for dir_name in os.listdir(flower_root):\n",
    "        path = os.path.join(flower_root, dir_name)\n",
    "        if os.path.isdir(path):\n",
    "          directories.append(path)\n",
    "          class_names.append(dir_name)\n",
    "\n",
    "      photo_filenames = []\n",
    "      for directory in directories:\n",
    "        for filename in os.listdir(directory):\n",
    "          path = os.path.join(directory, filename)\n",
    "          photo_filenames.append(path)\n",
    "\n",
    "      return photo_filenames, sorted(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/dan/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths, class_names = _get_filenames_and_classes(path)\n",
    "class_names_to_ids = dict(zip(class_names, range(len(class_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = tf.constant('/home/dan/datasets/flower_photos/sunflowers/14901528533_ac1ce09063.jpg')\n",
    "# image_string = tf.read_file(filename)\n",
    "# image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "# image_resized = tf.image.resize_images(image_decoded, [224, 224])\n",
    "# with tf.Session() as sess:\n",
    "#     image = sess.run(image_resized)    \n",
    "    \n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels = 3)\n",
    "    image_resized = tf.image.resize_images(image_decoded, [224, 224])\n",
    "    return image_resized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "batch_size = 64\n",
    "num_images = len(filepaths)\n",
    "\n",
    "dataset_filepath = tf.data.Dataset.from_tensor_slices(tf.cast(filepaths, tf.string))\n",
    "dataset_class = tf.data.Dataset.from_tensor_slices(\n",
    "    [class_names_to_ids[os.path.basename(os.path.dirname(filepath))] for filepath in filepaths])\n",
    "dataset = tf.data.Dataset.zip((dataset_filepath, dataset_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'IteratorGetNext:0' shape=(?, 224, 224, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.shuffle(num_images)\n",
    "dataset = dataset.repeat(epoch)\n",
    "dataset = dataset.map(_parse_function, num_parallel_calls=4)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.prefetch(2)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "print(next_element)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(1):\n",
    "        a = sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 224, 224, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "print(a[0].shape)\n",
    "print(a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 36.      ,  46.      ,  35.      ],\n",
       "        [ 30.375   ,  37.375   ,  29.375   ],\n",
       "        [ 16.142857,  22.214285,  15.142857],\n",
       "        ...,\n",
       "        [ 99.982544,  37.42871 ,  81.982544],\n",
       "        [140.57178 ,  52.142944, 121.500305],\n",
       "        [153.30365 ,  52.232117, 128.      ]],\n",
       "\n",
       "       [[ 35.486607,  47.486607,  34.513393],\n",
       "        [ 30.93168 ,  41.066963,  28.94603 ],\n",
       "        [ 19.624998,  26.885681,  18.103634],\n",
       "        ...,\n",
       "        [111.0479  ,  40.246063,  86.9724  ],\n",
       "        [145.53162 ,  53.890244, 124.23325 ],\n",
       "        [157.6729  ,  57.326305, 133.94823 ]],\n",
       "\n",
       "       [[ 36.973213,  49.94643 ,  33.026787],\n",
       "        [ 32.291134,  44.032204,  30.050861],\n",
       "        [ 23.555485,  32.585777,  21.623085],\n",
       "        ...,\n",
       "        [123.26658 ,  43.75744 ,  93.34694 ],\n",
       "        [151.643   ,  55.651894, 126.61455 ],\n",
       "        [164.47337 ,  64.17594 , 141.94382 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[110.379425, 117.45981 ,  78.91962 ],\n",
       "        [ 65.227264,  74.227264,  49.084408],\n",
       "        [ 20.325102,  28.599792,  17.674894],\n",
       "        ...,\n",
       "        [109.47632 ,  13.016267,  66.353355],\n",
       "        [170.669   ,  48.146294, 125.637085],\n",
       "        [210.94478 ,  83.65979 , 169.74998 ]],\n",
       "\n",
       "       [[105.94641 , 113.94641 ,  74.89282 ],\n",
       "        [ 61.818695,  70.81869 ,  45.63469 ],\n",
       "        [ 20.007006,  27.542719,  17.328434],\n",
       "        ...,\n",
       "        [ 94.29234 ,   5.770335,  50.26316 ],\n",
       "        [135.23404 ,  24.619106,  94.52883 ],\n",
       "        [185.73105 ,  59.922737, 147.55875 ]],\n",
       "\n",
       "       [[102.973206, 110.973206,  69.973206],\n",
       "        [ 58.098206,  67.098206,  40.419632],\n",
       "        [ 18.964283,  26.499998,  16.835781],\n",
       "        ...,\n",
       "        [ 87.568306,   5.139235,  42.121536],\n",
       "        [109.14649 ,  10.146154,  73.21284 ],\n",
       "        [161.10342 ,  37.68972 , 126.88195 ]]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
